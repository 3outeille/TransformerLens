{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracr to TransformerLens Converter\n",
    "[Tracr](https://github.com/deepmind/tracr) is a cool new DeepMind tool that compiles a written program in RASP to transformer weights. TransformerLens is a library I've written to easily do mechanistic interpretability on a transformer and to poke around at its internals. This is a (hacky!) script to convert Tracr weights from the JAX form to a TransformerLens HookedTransformer in PyTorch.\n",
    "\n",
    "See [the TransformerLens tutorial](https://neelnanda.io/transformer-lens-demo) to get started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python version must be >=3.8 (my fork of Tracr is a bit more backwards compatible, original library is at least 3.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.15\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install transformer_lens\n",
    "    # Fork of Tracr that's backward compatible with Python 3.8\n",
    "    %pip install git+https://github.com/neelnanda-io/tracr\n",
    "    \n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    # from IPython import get_ipython\n",
    "\n",
    "    # ipython = get_ipython()\n",
    "    # # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    # ipython.magic(\"load_ext autoreload\")\n",
    "    # ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import einops\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads an example RASP program model. This program reverses lists. The model takes as input a list of pre-tokenization elements (here `[\"BOS\", 1, 2, 3]`), these are tokenized (`[3, 0, 1, 2]`), the transformer is applied, and then an argmax is taken over the output and it is detokenized - this can be seen on the `out.decoded` attribute of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Creating a SequenceMap with both inputs being the same SOp is discouraged. You should use a Map instead.\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_length():\n",
    "  all_true_selector = rasp.Select(rasp.tokens, rasp.tokens, rasp.Comparison.TRUE)\n",
    "  return rasp.SelectorWidth(all_true_selector)\n",
    "\n",
    "\n",
    "length = make_length()  # `length` is not a primitive in our implementation.\n",
    "opp_index = length - rasp.indices - 1\n",
    "flip = rasp.Select(rasp.indices, opp_index, rasp.Comparison.EQ)\n",
    "reverse = rasp.Aggregate(flip, rasp.tokens)\n",
    "\n",
    "bos = \"BOS\"\n",
    "model = compiling.compile_rasp_to_model(\n",
    "    reverse,\n",
    "    vocab={1, 2, 3},\n",
    "    max_seq_len=5,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "\n",
    "out = model.apply([bos, 1, 2, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the model config from the Tracr model, and create a blank HookedTransformer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "n_heads = model.model_config.num_heads\n",
    "n_layers = model.model_config.num_layers\n",
    "d_head = model.model_config.key_size\n",
    "d_mlp = model.model_config.mlp_hidden_size\n",
    "act_fn = \"relu\"\n",
    "normalization_type = \"LN\"  if model.model_config.layer_norm else None\n",
    "attention_type = \"causal\"  if model.model_config.causal else \"bidirectional\"\n",
    "\n",
    "\n",
    "n_ctx = model.params[\"pos_embed\"]['embeddings'].shape[0]\n",
    "# Equivalent to length of vocab, with BOS and PAD at the end\n",
    "d_vocab = model.params[\"token_embed\"]['embeddings'].shape[0]\n",
    "# Residual stream width, I don't know of an easy way to infer it from the above config.\n",
    "d_model = model.params[\"token_embed\"]['embeddings'].shape[1]\n",
    "\n",
    "# Equivalent to length of vocab, WITHOUT BOS and PAD at the end because we never care about these outputs\n",
    "# In practice, we always feed the logits into an argmax\n",
    "d_vocab_out = model.params[\"token_embed\"]['embeddings'].shape[0] - 2\n",
    "\n",
    "cfg = HookedTransformerConfig(\n",
    "    n_layers=n_layers,\n",
    "    d_model=d_model,\n",
    "    d_head=d_head,\n",
    "    n_ctx=n_ctx,\n",
    "    d_vocab=d_vocab,\n",
    "    d_vocab_out=d_vocab_out,\n",
    "    d_mlp=d_mlp,\n",
    "    n_heads=n_heads,\n",
    "    act_fn=act_fn,\n",
    "    attention_dir=attention_type,\n",
    "    normalization_type=normalization_type,\n",
    ")\n",
    "tl_model = HookedTransformer(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the state dict, and do some reshaping so that everything has a n_heads dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pos_embed.W_pos', 'embed.W_E', 'unembed.W_U', 'blocks.0.attn.W_K', 'blocks.0.attn.b_K', 'blocks.0.attn.W_Q', 'blocks.0.attn.b_Q', 'blocks.0.attn.W_V', 'blocks.0.attn.b_V', 'blocks.0.attn.W_O', 'blocks.0.attn.b_O', 'blocks.0.mlp.W_in', 'blocks.0.mlp.b_in', 'blocks.0.mlp.W_out', 'blocks.0.mlp.b_out', 'blocks.1.attn.W_K', 'blocks.1.attn.b_K', 'blocks.1.attn.W_Q', 'blocks.1.attn.b_Q', 'blocks.1.attn.W_V', 'blocks.1.attn.b_V', 'blocks.1.attn.W_O', 'blocks.1.attn.b_O', 'blocks.1.mlp.W_in', 'blocks.1.mlp.b_in', 'blocks.1.mlp.W_out', 'blocks.1.mlp.b_out', 'blocks.2.attn.W_K', 'blocks.2.attn.b_K', 'blocks.2.attn.W_Q', 'blocks.2.attn.b_Q', 'blocks.2.attn.W_V', 'blocks.2.attn.b_V', 'blocks.2.attn.W_O', 'blocks.2.attn.b_O', 'blocks.2.mlp.W_in', 'blocks.2.mlp.b_in', 'blocks.2.mlp.W_out', 'blocks.2.mlp.b_out', 'blocks.3.attn.W_K', 'blocks.3.attn.b_K', 'blocks.3.attn.W_Q', 'blocks.3.attn.b_Q', 'blocks.3.attn.W_V', 'blocks.3.attn.b_V', 'blocks.3.attn.W_O', 'blocks.3.attn.b_O', 'blocks.3.mlp.W_in', 'blocks.3.mlp.b_in', 'blocks.3.mlp.W_out', 'blocks.3.mlp.b_out'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "sd = {}\n",
    "sd[\"pos_embed.W_pos\"] = model.params[\"pos_embed\"]['embeddings']\n",
    "sd[\"embed.W_E\"] = model.params[\"token_embed\"]['embeddings']\n",
    "# Equivalent to max_seq_len plus one, for the BOS\n",
    "\n",
    "# The unembed is just a projection onto the first few elements of the residual stream, these store output tokens\n",
    "# This is a NumPy array, the rest are Jax Arrays, but w/e it's fine.\n",
    "sd[\"unembed.W_U\"] = np.eye(d_model, d_vocab_out)\n",
    "\n",
    "for l in range(n_layers):\n",
    "    sd[f\"blocks.{l}.attn.W_K\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/key\"][\"w\"],\n",
    "        \"d_model (n_heads d_head) -> n_heads d_model d_head\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.b_K\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/key\"][\"b\"],\n",
    "        \"(n_heads d_head) -> n_heads d_head\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.W_Q\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/query\"][\"w\"],\n",
    "        \"d_model (n_heads d_head) -> n_heads d_model d_head\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.b_Q\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/query\"][\"b\"],\n",
    "        \"(n_heads d_head) -> n_heads d_head\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.W_V\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/value\"][\"w\"],\n",
    "        \"d_model (n_heads d_head) -> n_heads d_model d_head\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.b_V\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/value\"][\"b\"],\n",
    "        \"(n_heads d_head) -> n_heads d_head\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.W_O\"] = einops.rearrange(\n",
    "        model.params[f\"transformer/layer_{l}/attn/linear\"][\"w\"],\n",
    "        \"(n_heads d_head) d_model -> n_heads d_head d_model\",\n",
    "        d_head = d_head,\n",
    "        n_heads = n_heads\n",
    "    )\n",
    "    sd[f\"blocks.{l}.attn.b_O\"] = model.params[f\"transformer/layer_{l}/attn/linear\"][\"b\"]\n",
    "\n",
    "    sd[f\"blocks.{l}.mlp.W_in\"] = model.params[f\"transformer/layer_{l}/mlp/linear_1\"][\"w\"]\n",
    "    sd[f\"blocks.{l}.mlp.b_in\"] = model.params[f\"transformer/layer_{l}/mlp/linear_1\"][\"b\"]\n",
    "    sd[f\"blocks.{l}.mlp.W_out\"] = model.params[f\"transformer/layer_{l}/mlp/linear_2\"][\"w\"]\n",
    "    sd[f\"blocks.{l}.mlp.b_out\"] = model.params[f\"transformer/layer_{l}/mlp/linear_2\"][\"b\"]\n",
    "print(sd.keys())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weights to tensors and load into the tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['blocks.0.attn.mask', 'blocks.0.attn.IGNORE', 'blocks.1.attn.mask', 'blocks.1.attn.IGNORE', 'blocks.2.attn.mask', 'blocks.2.attn.IGNORE', 'blocks.3.attn.mask', 'blocks.3.attn.IGNORE', 'unembed.b_U'], unexpected_keys=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for k, v in sd.items():\n",
    "    # I cannot figure out a neater way to go from a Jax array to a numpy array lol\n",
    "    sd[k] = torch.tensor(np.array(v))\n",
    "\n",
    "tl_model.load_state_dict(sd, strict=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper functions to do the tokenization and de-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "INPUT_ENCODER = model.input_encoder\n",
    "OUTPUT_ENCODER = model.output_encoder\n",
    "\n",
    "def create_model_input(input, input_encoder=INPUT_ENCODER):\n",
    "    encoding = input_encoder.encode(input)\n",
    "    return torch.tensor(encoding).unsqueeze(dim=0)\n",
    "\n",
    "def decode_model_output(logits, output_encoder=OUTPUT_ENCODER, bos_token=INPUT_ENCODER.bos_token):\n",
    "    max_output_indices = logits.squeeze(dim=0).argmax(dim=-1)\n",
    "    decoded_output = output_encoder.decode(max_output_indices.tolist())\n",
    "    decoded_output_with_bos = [bos_token] + decoded_output[1:]\n",
    "    return decoded_output_with_bos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Decoding: ['BOS', 3, 2, 1]\n",
      "TransformerLens Replicated Decoding: ['BOS', 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = [bos, 1, 2, 3]\n",
    "out = model.apply(input)\n",
    "print(\"Original Decoding:\", out.decoded)\n",
    "\n",
    "input_tokens_tensor = create_model_input(input)\n",
    "logits = tl_model(input_tokens_tensor)\n",
    "decoded_output = decode_model_output(logits)\n",
    "print(\"TransformerLens Replicated Decoding:\", decoded_output)\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6970b9bc1f22c1555ce2e3aef3e9bc8c56c5727cd75cae357902c75ead4068e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
